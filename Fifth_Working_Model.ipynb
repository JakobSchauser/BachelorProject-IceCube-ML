{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Fifth Working Model",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1F5LapnzmQ3_-UbqgwUGvW0joIZtifhJc",
      "authorship_tag": "ABX9TyOIpU0188/bVw4HX8I1bN+v",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JakobSchauser/BachelorProject-IceCube-ML/blob/main/Fifth_Working_Model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mKMo6IdMfBDD"
      },
      "source": [
        "!pip install spektral -q\r\n",
        "\r\n",
        "import numpy as np\r\n",
        "import tensorflow as tf\r\n",
        "import keras\r\n",
        "import pickle\r\n",
        "import spektral\r\n",
        "\r\n",
        "from tensorflow.keras.layers import Dense, Input\r\n",
        "from tensorflow.keras.losses import MeanSquaredError, MeanAbsoluteError\r\n",
        "from tensorflow.keras.metrics import MeanAbsoluteError as MeanAbsoluteError_acc\r\n",
        "from tensorflow.keras.models import Model\r\n",
        "from tensorflow.keras.optimizers import Adam\r\n",
        "from tensorflow.sparse import SparseTensor\r\n",
        "\r\n",
        "\r\n",
        "from time import time\r\n",
        "\r\n",
        "\r\n",
        "from spektral.data import DisjointLoader, Dataset\r\n",
        "from spektral.datasets import QM9\r\n",
        "from spektral.layers import AGNNConv, GlobalSumPool, GlobalMaxPool, GlobalAvgPool, GCNConv, ECCConv\r\n",
        "\r\n",
        "from tqdm.notebook import tqdm\r\n",
        "\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "import seaborn as sns\r\n",
        "sns.set()\r\n",
        "%matplotlib inline\r\n",
        "\r\n",
        "PI = np.pi\r\n",
        "\r\n",
        "\r\n",
        "# Lifehack\r\n",
        "true = True\r\n",
        "false = False"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jRsrlI0nNqIq",
        "outputId": "1901d95a-1530-46b6-87c2-8f262ac575fd"
      },
      "source": [
        "!pip install wandb -q\r\n",
        "\r\n",
        "import wandb\r\n",
        "from wandb.keras import WandbCallback\r\n",
        "\r\n",
        "wandb.login()"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mjakobschauser\u001b[0m (use `wandb login --relogin` to force relogin)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2gQ8LBcAfIm7",
        "outputId": "8c5a88a4-a4b3-4f86-e1f0-f7b4be008270"
      },
      "source": [
        "################################################################################\r\n",
        "# LOAD DATA\r\n",
        "################################################################################\r\n",
        "# Find the reverse transformer\r\n",
        "pcl = \"/content/drive/MyDrive/Bachelor Project - IceCube ML/transformers.pkl\"\r\n",
        "\r\n",
        "with open(pcl,'rb') as tra:\r\n",
        "    transformer = pickle.load(tra)\r\n",
        "\r\n",
        "transformer = transformer[\"truth\"]\r\n",
        "\r\n",
        "\r\n",
        "class dat(Dataset):\r\n",
        "  def __init__(self,n = 1,**kwargs):\r\n",
        "    self.n = n\r\n",
        "    super().__init__(**kwargs)\r\n",
        "  def read(self):\r\n",
        "    # path = \"/content/drive/MyDrive/Bachelor Project - IceCube ML/generatedDataAnglesEnergy100000 0.npz\" # Uncleaned\r\n",
        "    path = \"/content/drive/MyDrive/Bachelor Project - IceCube ML/generatedDataAnglesEnergyClean200000events 0.npz\" # Cleaned\r\n",
        "    # path = \"/content/drive/MyDrive/Bachelor Project - IceCube ML/data.dat\" # From Severin\r\n",
        "    dataset = np.load(path,allow_pickle = True)[\"arr_0\"]\r\n",
        "    graphs = []\r\n",
        "    for g in dataset:\r\n",
        "      e,a,z = g[\"y\"]\r\n",
        "      g[\"y\"] = [transformer['energy_log10'].transform([[e]])[0][0],transformer['zenith'].transform([[a]])[0][0],transformer['azimuth'].transform([[z]])[0][0]]\r\n",
        "      graphs.append(g)\r\n",
        "    return np.array(dataset)\r\n",
        "\r\n",
        "dataset = dat()\r\n",
        "\r\n",
        "print(\"Dataset is\", dataset, \"consisting of\", dataset[0])\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "#### Put on GPU when possible\r\n",
        "physical_devices = tf.config.list_physical_devices('GPU')\r\n",
        "if len(physical_devices) > 0:\r\n",
        "    print(\"Running on GPU\")\r\n",
        "    tf.config.experimental.set_memory_growth(physical_devices[0], True)\r\n",
        "else:\r\n",
        "    print(\"Running on CPU\")"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/base.py:318: UserWarning: Trying to unpickle estimator RobustScaler from version 0.19.1 when using version 0.22.2.post1. This might lead to breaking code or invalid results. Use at your own risk.\n",
            "  UserWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Dataset is dat(n_graphs=200000) consisting of Graph(n_nodes=13, n_node_features=5, n_edge_features=None, n_labels=3)\n",
            "Running on GPU\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4FEPaDtqysJ1"
      },
      "source": [
        "from spektral.transforms import GCNFilter\r\n",
        "\r\n",
        "t = time.time()\r\n",
        "dataset.apply(GCNFilter())\r\n",
        "print(f\"Goddamn, this takes {t-time.time():.3} seconds!\")"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QtXbVD-LfZr6"
      },
      "source": [
        "def custom_loss(target,predictions):\r\n",
        "    predictions = tf.cast(predictions,\"float64\")\r\n",
        "\r\n",
        "    energy = tf.abs(target[:,0] - predictions[:,0])\r\n",
        "\r\n",
        "    azi  = [tf.cos(target[:,1]) - predictions[:,1] , \r\n",
        "            tf.sin(target[:,1]) - predictions[:,2]]\r\n",
        "\r\n",
        "    zeni = [tf.cos(target[:,2]) - predictions[:,3] , \r\n",
        "            tf.sin(target[:,2]) - predictions[:,4]]\r\n",
        "\r\n",
        "\r\n",
        "    loss = 0\r\n",
        "    loss += tf.reduce_mean(tf.square(energy))\r\n",
        "    loss += tf.reduce_mean(tf.square(azi[0]))\r\n",
        "    loss += tf.reduce_mean(tf.square(azi[1]))\r\n",
        "    loss += tf.reduce_mean(tf.square(zeni[0]))\r\n",
        "    loss += tf.reduce_mean(tf.square(zeni[1]))\r\n",
        "    loss += 0.1\r\n",
        "    return loss\r\n",
        "\r\n",
        "loss_fn = custom_loss\r\n",
        "\r\n",
        "\r\n",
        "def custom_acc(target,predictions):\r\n",
        "    predictions = tf.cast(predictions,\"float64\")\r\n",
        "\r\n",
        "    \r\n",
        "    energy    = tf.abs(target[:,0] - predictions[:,0])\r\n",
        "\r\n",
        "    aziguess = tf.atan2(predictions[:,2],predictions[:,1])\r\n",
        "    azi = tf.minimum( tf.abs(target[:,1] - aziguess) , tf.abs(tf.abs(target[:,1] - aziguess) - 2*PI))\r\n",
        "\r\n",
        "    zeniguess = tf.atan2(predictions[:,4],predictions[:,3])\r\n",
        "    zeni = tf.minimum( tf.abs(target[:,2] - zeniguess) , tf.abs(tf.abs(target[:,2] - zeniguess) - 2*PI))\r\n",
        "    \r\n",
        "\r\n",
        "    return (energy,azi,zeni)\r\n",
        "\r\n",
        "def scale_inputs(inputs):\r\n",
        "    inputs[0][:,:3] = inputs[0][:,:3]/100 # x y z\r\n",
        "    inputs[0][:,3] = inputs[0][:,3]/10000 # time\r\n",
        "    inputs[0][:,4] = inputs[0][:,4]/1 # charge\r\n",
        "    return inputs\r\n",
        "\r\n",
        "\r\n"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gnzJXaA9a1HR"
      },
      "source": [
        "################################################################################\r\n",
        "# PARAMETERS\r\n",
        "################################################################################\r\n",
        "#@markdown ### Define the model and training parameters and sync with WandB\r\n",
        "batch_size =  32#@param {type: \"number\"}\r\n",
        "\r\n",
        "# one-variable network size changer\r\n",
        "network_size =  64#@param {type: \"number\"}\r\n",
        "\r\n",
        "learning_rate = 2e-4  #@param {type: \"number\"}\r\n",
        "\r\n",
        "training_epochs = 12 #@param {type: \"slider\", min: 10, max: 200}\r\n",
        "\r\n",
        "\r\n",
        "loss_function = \"rasmus_loss\"  #@param ['custom_loss',\"rasmus_loss\"]\r\n",
        "\r\n",
        "config = {\r\n",
        "        \"learning_rate\": learning_rate,\r\n",
        "        \"epochs\": training_epochs,\r\n",
        "        \"batch_size\": batch_size,\r\n",
        "        \"loss_function\": loss_function,\r\n",
        "        \"architecture\": \"Broadening CNN - short but wide\",\r\n",
        "        \"network_size\": network_size,\r\n",
        "        \"dataset\": \"MuonGun\"\r\n",
        "      }\r\n",
        "\r\n",
        "epochs = config[\"epochs\"]  # Number of training epochs\r\n",
        "test_epochs = 2 # Number of testing epochs\r\n",
        "\r\n"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y5n3nAsOi5Dt"
      },
      "source": [
        "# Parameters\r\n",
        "F = dataset.n_node_features  # Dimension of node features\r\n",
        "S = dataset.n_edge_features  # Dimension of edge features\r\n",
        "# n_out = dataset.n_labels  # Dimension of the target\r\n",
        "n_out = 5\r\n",
        "\r\n",
        "# Train/test split\r\n",
        "idxs = np.random.permutation(len(dataset))\r\n",
        "split = int(0.9 * len(dataset))\r\n",
        "idx_tr, idx_te = np.split(idxs, [split])\r\n",
        "dataset_tr, dataset_te = dataset[idx_tr], dataset[idx_te]\r\n",
        "\r\n",
        "train_loader = DisjointLoader(dataset_tr, batch_size=batch_size, epochs=epochs, shuffle=True)\r\n",
        "test_loader = DisjointLoader(dataset_te, batch_size=batch_size, epochs=test_epochs, shuffle=True)\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "class model_class(Model):\r\n",
        "  def __init__(self):\r\n",
        "    super().__init__()\r\n",
        "    \r\n",
        "\r\n",
        "    self.conv = GCNConv(network_size//4,activation=\"gelu\")\r\n",
        "    self.conv1 = GCNConv(network_size//2,activation=\"gelu\")\r\n",
        "\r\n",
        "    self.maxpool = GlobalMaxPool()\r\n",
        "    self.avgpool = GlobalAvgPool()\r\n",
        "    self.sumpool = GlobalSumPool()\r\n",
        "\r\n",
        "    self.largedense= Dense(network_size)\r\n",
        "    self.mediumdense= Dense(network_size//2)\r\n",
        "                           \r\n",
        "    self.smalldense = Dense(network_size//4)\r\n",
        "\r\n",
        "    self.out = Dense(n_out)\r\n",
        " \r\n",
        "\r\n",
        "  def call(self, inputs, training = False):\r\n",
        "    x, a, i = inputs\r\n",
        "    # a, e    = self.generate_edge_features(x, a) # NEXT STEP is implementing this for myself\r\n",
        "    # x = self.inp([x,a,e])\r\n",
        "    x = self.conv([x,a])\r\n",
        "    x = self.conv1([x,a])\r\n",
        "    \r\n",
        "    xm = self.maxpool([x,i])\r\n",
        "    xa = self.avgpool([x,i])\r\n",
        "    xs = self.sumpool([x,i])\r\n",
        "\r\n",
        "    x = tf.concat([xm, xa, xs], axis = 1) \r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "    x = self.largedense(x)\r\n",
        "    x = self.mediumdense(x)\r\n",
        "    x = self.smalldense(x)\r\n",
        "\r\n",
        "    out = self.out(x)\r\n",
        "\r\n",
        "    return out\r\n",
        "    # return oute,outa,outz\r\n",
        "\r\n",
        "  #Shamelessly stolen from Johann\r\n",
        "  def generate_edge_features(self, x, a):\r\n",
        "      send    = a.indices[:, 0]\r\n",
        "      receive = a.indices[:, 1]\r\n",
        "\r\n",
        "      diff_x  = tf.subtract(tf.gather(x, receive), tf.gather(x, send))\r\n",
        "\r\n",
        "      dists   = tf.sqrt(\r\n",
        "        tf.reduce_sum(\r\n",
        "          tf.square(\r\n",
        "            diff_x[:, :3]\r\n",
        "          ), axis = 1\r\n",
        "        ))\r\n",
        "\r\n",
        "      vects = tf.math.divide_no_nan(diff_x[:, :3], tf.expand_dims(dists, axis = -1))\r\n",
        "\r\n",
        "      e = tf.concat([diff_x[:, 3:], tf.expand_dims(dists, -1), vects], axis = 1)\r\n",
        "\r\n",
        "      return a, e\r\n",
        "\r\n",
        "# Build model\r\n",
        "model = model_class()\r\n",
        "\r\n",
        "opt = Adam(lr=learning_rate)\r\n",
        "loss_fn = custom_loss\r\n",
        "# loss_fn = MeanAbsoluteError()\r\n",
        "acc_fn = MeanAbsoluteError()\r\n",
        "\r\n",
        "\r\n",
        "model.compile()\r\n",
        "# model.build()\r\n",
        "# fit(train_loader)"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C_Y52q67_kNR"
      },
      "source": [
        "################################################################################\r\n",
        "# DEFINE TF-FUNCTIONS\r\n",
        "################################################################################\r\n",
        "@tf.function(input_signature=train_loader.tf_signature(), experimental_relax_shapes=True)\r\n",
        "def train_step(inputs, target):\r\n",
        "    with tf.GradientTape() as tape:\r\n",
        "        predictions = model(inputs, training=True)\r\n",
        "        loss = loss_fn(target, predictions)\r\n",
        "        loss += sum(model.losses)\r\n",
        "    gradients = tape.gradient(loss, model.trainable_variables)\r\n",
        "    opt.apply_gradients(zip(gradients, model.trainable_variables))\r\n",
        "    acc = acc_fn(target,predictions)\r\n",
        "\r\n",
        "    return loss, acc\r\n",
        "\r\n",
        "def validate(inputs,target):\r\n",
        "    predictions = model(inputs, training=False)\r\n",
        "    loss = loss_fn(target, predictions)\r\n",
        "    loss += sum(model.losses)\r\n",
        "    acc = acc_fn(target,predictions)\r\n",
        "\r\n",
        "    return loss, acc\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "loss_fn = custom_loss\r\n",
        "acc_fn = custom_acc\r\n",
        "def fit(train_loader,logwandb = False):\r\n",
        "  if logwandb:\r\n",
        "    run = wandb.init(project='IceCube GNN Bachelor',config = config)\r\n",
        "\r\n",
        "  current_batch = 0\r\n",
        "  model_loss = []\r\n",
        "  model_acc = []\r\n",
        "  vali_loss = []\r\n",
        "  epoch = 0\r\n",
        "\r\n",
        "  epoch_steps = train_loader.steps_per_epoch\r\n",
        "\r\n",
        "  t = tqdm(total  = train_loader.steps_per_epoch,leave = True)\r\n",
        "  t.set_description(f'Currently on epoch {0} of {epochs} ')\r\n",
        "\r\n",
        "  pb = []\r\n",
        "  tar = []\r\n",
        "  step = 0\r\n",
        "\r\n",
        "  last_loss = 0\r\n",
        "  \r\n",
        "  for batch in train_loader:\r\n",
        "      step += 1\r\n",
        "      inputs, target = batch\r\n",
        "      inputs = scale_inputs(inputs)\r\n",
        "\r\n",
        "      loss, acc = train_step(inputs,target)\r\n",
        "\r\n",
        "      model_loss.append(loss)\r\n",
        "      model_acc.append(acc)\r\n",
        "      current_batch += 1\r\n",
        "      t.update(1)\r\n",
        "\r\n",
        "      if current_batch == epoch_steps:\r\n",
        "          test_loader = DisjointLoader(dataset_te, batch_size=batch_size, epochs=test_epochs, shuffle=True)\r\n",
        "          t.set_description(f'Currently validating results')\r\n",
        "\r\n",
        "          for vali_batch in test_loader:\r\n",
        "            vali_inputs, vali_target = vali_batch\r\n",
        "            valie_inputs = scale_inputs(vali_inputs)\r\n",
        "            valoss, vaacc = validate(vali_inputs,vali_target)\r\n",
        "            vali_loss.append(valoss)\r\n",
        "          va = np.mean(vali_loss)\r\n",
        "\r\n",
        "          m_loss = np.mean(model_loss)\r\n",
        "          change = (m_loss-last_loss)/max(0.000001,last_loss)\r\n",
        "          last_loss = m_loss\r\n",
        "\r\n",
        "          s = \"Train loss: {} - Loss change {:+.3f}% | Validation loss {} | Epoch: {}\".format(m_loss, change*100,va, epoch)\r\n",
        "          t.write(s)\r\n",
        "\r\n",
        "          ma = np.array(model_acc)\r\n",
        "          s = \"Accuracy is: Energy {} | Azimuth {} | Zenith {}\\n\".format(np.mean(ma[:,0]),np.mean(ma[:,1]),np.mean(ma[:,2]))\r\n",
        "          t.write(s)\r\n",
        "          # print(\"Two current guesses are\\n\",np.array(pb[0]),np.array(pb[1]),\"for\\n\",tar[0],tar[1])\r\n",
        "\r\n",
        "          # if epoch%5 == 0 and epoch != 0:\r\n",
        "            # print(\"Two current guesses are\\n\",np.array(pb[0]),np.array(pb[1]),\"for\\n\",tar[0],tar[1])\r\n",
        "            # pass\r\n",
        "          # else:\r\n",
        "            # pb = model(inputs, training=False)\r\n",
        "            # tar = target\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "          if logwandb:\r\n",
        "            wandb.log({\r\n",
        "                      \"train_loss\": m_loss,\r\n",
        "                      \"energy_accuracy\": np.mean(ma[:,0]),\r\n",
        "                      \"azimuth_accuracy\": np.mean(ma[:,1]),\r\n",
        "                      \"zenith_accuracy\": np.mean(ma[:,2]),\r\n",
        "                      \"val_loss\": va,\r\n",
        "                      })\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "          model_loss = []\r\n",
        "          model_acc = []\r\n",
        "          vali_acc = []\r\n",
        "          current_batch = 0\r\n",
        "          step = 0\r\n",
        "\r\n",
        "          t.n = 0\r\n",
        "          t.last_print_n = 0\r\n",
        "          t.refresh()\r\n",
        "          epoch += 1\r\n",
        "\r\n",
        "          t.set_description(f'Currently on epoch {epoch} of {epochs} ')\r\n"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7E3bDUpo_tue",
        "outputId": "f133f405-d943-48b3-b0d7-7e90c156acdb"
      },
      "source": [
        "logwandb = True\r\n",
        "\r\n",
        "fit(train_loader,logwandb = logwandb)\r\n",
        "\r\n",
        "print(\"\\n\\nTraining of the following model is now complete:\")\r\n",
        "model.summary()\r\n",
        "save_path = \"/content/drive/MyDrive/Bachelor Project - IceCube ML/Saved Models\"\r\n",
        "pth = save_path + f\"/{wandb.run.name}-{int(epochs)}epochs\"\r\n",
        "model.save(pth)\r\n",
        "\r\n",
        "if logwandb:\r\n",
        "  wandb.run.finish()  "
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "Training of the following model is now complete:\n",
            "Model: \"model_class_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "gcn_conv_2 (GCNConv)         multiple                  80        \n",
            "_________________________________________________________________\n",
            "gcn_conv_3 (GCNConv)         multiple                  512       \n",
            "_________________________________________________________________\n",
            "global_max_pool_1 (GlobalMax multiple                  0         \n",
            "_________________________________________________________________\n",
            "global_avg_pool_1 (GlobalAvg multiple                  0         \n",
            "_________________________________________________________________\n",
            "global_sum_pool_1 (GlobalSum multiple                  0         \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              multiple                  6208      \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              multiple                  2080      \n",
            "_________________________________________________________________\n",
            "dense_6 (Dense)              multiple                  528       \n",
            "_________________________________________________________________\n",
            "dense_7 (Dense)              multiple                  85        \n",
            "=================================================================\n",
            "Total params: 9,493\n",
            "Trainable params: 9,493\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/Bachelor Project - IceCube ML/Saved Models/helpful-water-62-12epochs/assets\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ka1sa9P2yVfX",
        "outputId": "e4cc0798-e5f0-4e2e-e5a6-d9f203aab7f1"
      },
      "source": [
        "\r\n",
        "# keras.models.load_model(\"/content/drive/MyDrive/Bachelor Project - IceCube ML/Saved Models/astral-valley-61-52epochs\")\r\n",
        "\r\n",
        "@tf.function(input_signature=test_loader.tf_signature(), experimental_relax_shapes=True)\r\n",
        "def get_predictions(inputs,target):\r\n",
        "  return model(inputs,training = False)\r\n",
        "\r\n",
        "def get_true_guesses(inputs,target):\r\n",
        "  pred = model(inputs,training = False)\r\n",
        "  energy = pred[:,0]\r\n",
        "  azi  = tf.atan2(pred[:,2],pred[:,1])\r\n",
        "  zeni = tf.atan2(pred[:,4],pred[:,3])\r\n",
        "  return (energy,azi,zeni)\r\n",
        "\r\n",
        "\r\n",
        "def make1D(a):\r\n",
        "  new = []\r\n",
        "  for aa in a:\r\n",
        "    for aaa in aa:\r\n",
        "      new.append(aaa)\r\n",
        "  return np.array(new)\r\n",
        "\r\n",
        "def test_model():\r\n",
        "  print(\"Testing model\")\r\n",
        "  model_loss, model_acc = [],[]\r\n",
        "\r\n",
        "  test_loader = DisjointLoader(dataset_te, batch_size=batch_size, epochs=10,shuffle = True)\r\n",
        "\r\n",
        "  predictions, truths = [],[]\r\n",
        "\r\n",
        "  for batch in tqdm(test_loader):\r\n",
        "    inputs, target = batch\r\n",
        "    inputs = scale_inputs(inputs) \r\n",
        "    # print(inputs)\r\n",
        "    pred = get_predictions(inputs,target)\r\n",
        "\r\n",
        "    true_guesses = get_true_guesses(inputs,target)\r\n",
        "\r\n",
        "    predictions.append(true_guesses)\r\n",
        "    truths.append(np.array(target))\r\n",
        "    \r\n",
        "    # print(pred)\r\n",
        "    model_loss.append(loss_fn(target, np.array(pred)))\r\n",
        "    model_acc.append(acc_fn(target, pred))\r\n",
        "  \r\n",
        "  model_acc = np.array(model_acc)\r\n",
        "  print(f\"Done! \\nModel loss {np.mean(model_loss)} | Energy accuracy {np.mean(model_acc[:,0])} | Azimuth accuracy {np.mean(model_acc[:,1])} | Zenith accuracy {np.mean(model_acc[:,2])}\")\r\n",
        "  return predictions, truths\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "predictions, truths = test_model()"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Done! \n",
            "Model loss 0.38445007464640835 | Energy accuracy 0.17099874740852977 | Azimuth accuracy 0.42744643163172613 | Zenith accuracy 0.06734332301411895\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 377
        },
        "id": "KkQzrIPNSQ0j",
        "outputId": "e43d6632-dbdd-4bbb-c17b-f41e3230768d"
      },
      "source": [
        "preds, trs = [],[]\r\n",
        "\r\n",
        "\r\n",
        "for p,t in zip(predictions,truths):\r\n",
        "  preds.append(np.array(p[0]))\r\n",
        "  trs.append(np.array(t)[:,0])\r\n",
        "\r\n",
        "trs = np.array(trs).flatten()\r\n",
        "preds = np.array(preds).flatten()\r\n",
        "\r\n",
        "preds = preds[np.where(preds<0)]\r\n",
        "\r\n",
        "\r\n",
        "plt.figure(figsize=(14,6))\r\n",
        "plt.hist(trs,bins=50,histtype=\"step\",cumulative=False)\r\n",
        "plt.hist(preds,bins=50,histtype=\"step\",cumulative=False)\r\n",
        "# plt.yscale(\"log\")\r\n",
        "plt.show()"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1008x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "74ChDcxA613C",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7ddb9a9f-1f5e-4bc8-acc3-9d6405b3fe71"
      },
      "source": [
        "np.array(trs).flatten()"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([-1.30662026, -1.23758388, -1.13238841, ..., -0.86201091,\n",
              "       -0.85135644, -1.13864522])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    }
  ]
}