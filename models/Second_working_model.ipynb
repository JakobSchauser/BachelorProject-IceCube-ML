{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Second working model",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "43e770fbedc14903adafb77dca1f7c56": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_904167b77cbc4900868b7a33782858ae",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_89c94007491f4dd68b0c0da9420b7ffc",
              "IPY_MODEL_a673b59f357747ef924d8fa54b50d414"
            ]
          }
        },
        "904167b77cbc4900868b7a33782858ae": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "89c94007491f4dd68b0c0da9420b7ffc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_551b89e1db2840ca9dfe975971179949",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "danger",
            "max": 2667,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 2667,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_a53865e787d14e8ebd3400afc4f66331"
          }
        },
        "a673b59f357747ef924d8fa54b50d414": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_1eebe7523ce4404eaeaff32e69ea1a52",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 10294/? [02:38&lt;00:00, 70.08it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_bf81af2b542c4ceeb113e666944b8e04"
          }
        },
        "551b89e1db2840ca9dfe975971179949": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "a53865e787d14e8ebd3400afc4f66331": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "1eebe7523ce4404eaeaff32e69ea1a52": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "bf81af2b542c4ceeb113e666944b8e04": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JakobSchauser/BachelorProject-IceCube-ML/blob/main/Second_working_model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ORWGFwwPOkpj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "00454871-455d-4124-9678-eff6cc89c8cc"
      },
      "source": [
        "!pip install spektral -q"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[?25l\r\u001b[K     |██▉                             | 10kB 18.0MB/s eta 0:00:01\r\u001b[K     |█████▋                          | 20kB 22.0MB/s eta 0:00:01\r\u001b[K     |████████▌                       | 30kB 9.6MB/s eta 0:00:01\r\u001b[K     |███████████▎                    | 40kB 7.6MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 51kB 4.4MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 61kB 4.9MB/s eta 0:00:01\r\u001b[K     |███████████████████▊            | 71kB 5.0MB/s eta 0:00:01\r\u001b[K     |██████████████████████▋         | 81kB 5.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▍      | 92kB 5.6MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▏   | 102kB 5.4MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 112kB 5.4MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 122kB 5.4MB/s \n",
            "\u001b[?25h"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zS4QNMbFJD0x"
      },
      "source": [
        "# Mainly following the semi-official example code from \r\n",
        "# https://github.com/danielegrattarola/spektral/blob/master/examples/node_prediction/citation_simple_gc.py\r\n",
        "import numpy as np\r\n",
        "\r\n",
        "from tensorflow.keras.callbacks import EarlyStopping\r\n",
        "from tensorflow.keras.layers import Input, Dense\r\n",
        "from tensorflow.keras.models import Model\r\n",
        "from tensorflow.keras.optimizers import Adam\r\n",
        "from tensorflow.keras.regularizers import l2\r\n",
        "\r\n",
        "from spektral.data.loaders import BatchLoader, SingleLoader, DisjointLoader\r\n",
        "from spektral.datasets.citation import Citation\r\n",
        "from spektral.layers import GCNConv, ECCConv, GlobalSumPool, GlobalMaxPool\r\n",
        "from spektral.transforms import LayerPreprocess, AdjToSpTensor\r\n",
        "from spektral.data import Dataset, Graph\r\n",
        "from spektral.models import GeneralGNN\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "from spektral.data import Dataset\r\n",
        "from tqdm.notebook import tqdm\r\n",
        "\r\n",
        "import tensorflow as tf\r\n",
        "\r\n",
        "#Lifehack\r\n",
        "true = True\r\n",
        "false = False"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YRi5T_rMJq_S"
      },
      "source": [
        "\r\n",
        "# Start out by loading data\r\n",
        "class dat(Dataset):\r\n",
        "  def __init__(self,n = 1,**kwargs):\r\n",
        "    self.n = n\r\n",
        "    super().__init__(**kwargs)\r\n",
        "  def read(self):\r\n",
        "    # path = \"/content/drive/MyDrive/Bachelor Project - IceCube ML/generatedDataEnergy100000 0.npz\"\r\n",
        "    path = \"/content/drive/MyDrive/Bachelor Project - IceCube ML/data.dat\"\r\n",
        "    dataset = np.load(path,allow_pickle = True)#[\"arr_0\"]\r\n",
        "    graphs = []\r\n",
        "    for g in dataset:\r\n",
        "      graphs.append(g)\r\n",
        "    return np.array(dataset)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rFIfrXQ-3Vbq",
        "outputId": "5783ed62-b587-4a5c-a623-07324deda92e"
      },
      "source": [
        "dataset = dat()\r\n",
        "print(dataset,\"\\n\",dataset[0])"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "dat(n_graphs=100000) \n",
            " Graph(n_nodes=34, n_node_features=5, n_edge_features=None, n_labels=7)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yqg9Iq6mJzJG"
      },
      "source": [
        "# Setting up the model training parameter\r\n",
        "\r\n",
        "learning_rate = 0.05    \r\n",
        "epochs = 1000\r\n",
        "early_stopping_patience = 50\r\n",
        "\r\n",
        "batch_size = 30\r\n",
        "\r\n",
        "N_nodes = dataset.n_nodes\r\n",
        "N_features = dataset.n_node_features\r\n",
        "\r\n",
        "n_out = dataset.n_labels"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hfi3ilwvtM9L"
      },
      "source": [
        "# Trying to recreate a DCN from \r\n",
        "# https://www.asimovinstitute.org/neural-network-zoo/\r\n",
        "\r\n",
        "# Define the model\r\n",
        "size = 32\r\n",
        "\r\n",
        "X_in = Input(shape = (N_features,), name = \"X_in\")\r\n",
        "A_in = Input(shape = (None,), sparse = True, name = \"A_in\")\r\n",
        "I_in = Input(shape = (), name=\"segment_ids_in\", dtype=tf.int32)\r\n",
        "\r\n",
        "x = GCNConv(size,activation=\"relu\")([X_in,A_in])\r\n",
        "x = GCNConv(size//2,activation=\"relu\")([x,A_in])\r\n",
        "x = GCNConv(size//2,activation=\"relu\")([x,A_in])\r\n",
        "x = GCNConv(size//2,activation=\"relu\")([x,A_in])\r\n",
        "x = GCNConv(batch_size,activation=\"relu\")([x,A_in])\r\n",
        "\r\n",
        "# x = Dense(size,activation=\"relu\")(x)\r\n",
        "# x = Dense(size,activation=\"relu\")(x)\r\n",
        "# x = Dense(size)(x)\r\n",
        "\r\n",
        "x_out = GlobalSumPool()([x,I_in])\r\n",
        "\r\n",
        "output = Dense(n_out)(x_out)\r\n",
        "# Build the model\r\n",
        "model = Model(inputs = [X_in,A_in,I_in], outputs = output)\r\n",
        "\r\n",
        "\r\n",
        "acc_func = tf.keras.metrics.mean_absolute_error\r\n",
        "loss_func = tf.losses.mean_squared_error\r\n",
        "\r\n",
        "\r\n",
        "# Ignore this for the time being\r\n",
        "# class model(Model):\r\n",
        "#   def __init__(self,n_out):\r\n",
        "#     super().__init__(activation=activation, aggregate = \"mean\")\r\n",
        "#     self.n_out = n_out\r\n",
        "  \r\n",
        "#   def build(self, input_shape):\r\n",
        "#     n_in = input_shape[0]\r\n",
        "#     self.weights = self.add_weight(shape=(n_in,self.n_out))\r\n",
        "\r\n",
        "#   def call(self, inputs):\r\n",
        "#     x, a = inputs\r\n",
        "\r\n",
        "#     x = tf.matmul(x, self.weights)\r\n",
        "\r\n",
        "#   def update(self,embeddings):\r\n",
        "#     return self.activation(embeddings)\r\n",
        "# output = GCNConv(n_out, activation='softmax',use_bias = False)([x_in, a_in]) # maybe add use_bias = False\r\n",
        "\r\n",
        "# model = Model(inputs=[x_in, a_in], outputs=output)\r\n",
        "# model = GeneralGCN(dataset.n_labels,activation=\"softmax\",) # Using softmax now. Maybe gelu would be better. Maybe add pool = sum\r\n",
        "\r\n",
        "optimizer = Adam(lr=learning_rate)\r\n",
        "\r\n",
        "\r\n",
        "split = int(len(dataset)*0.8)\r\n",
        "traindat, testdat = dataset[:split], dataset[split:]\r\n",
        "\r\n",
        "\r\n",
        "train_loader = DisjointLoader(traindat,epochs=epochs,batch_size = batch_size,shuffle = True) \r\n",
        "test_loader  = DisjointLoader(testdat,epochs=1,batch_size = batch_size,shuffle = True)\r\n",
        "# model.summary()\r\n",
        "\r\n",
        "\r\n",
        "# Training step function\r\n",
        "@tf.function(input_signature=train_loader.tf_signature(),experimental_relax_shapes=True)\r\n",
        "def train_on_batch(inputs,target): \r\n",
        "  with tf.GradientTape() as tape:\r\n",
        "    predictions = model(inputs,training = True)\r\n",
        "    loss = loss_func(target,predictions) + sum(model.losses)#+0.01\r\n",
        "    acc = acc_func(target,predictions)\r\n",
        "  \r\n",
        "  gradients = tape.gradient(loss,model.trainable_variables)\r\n",
        "  optimizer.apply_gradients(zip(gradients,model.trainable_variables))\r\n",
        "  return loss, acc\r\n",
        "\r\n",
        "# Evaluating function \r\n",
        "def evaluate(loader):\r\n",
        "  step = 0\r\n",
        "  results = []\r\n",
        "  for batch in loader:\r\n",
        "    step += 1\r\n",
        "    inputs, target = batch\r\n",
        "    predictions = model(inputs, training = False)\r\n",
        "    loss = loss_func(target,predictions) + sum(model.losses)+0.01\r\n",
        "    acc = acc_func(target,predictions)\r\n",
        "    l = [np.mean(loss),np.mean(acc)]\r\n",
        "    results.append(l)\r\n",
        "    # if step == loader.steps_per_epoch:\r\n",
        "    results = np.array(results)\r\n",
        "    loss, acc = np.mean(results[:,0]), np.mean(results[:,1])\r\n",
        "    return np.array([loss, acc])\r\n",
        "  \r\n",
        "\r\n",
        "\r\n",
        "#Doing the full training\r\n",
        "\r\n",
        "def train_model(train_loader, test_loader):\r\n",
        "  print('Training model.')\r\n",
        "\r\n",
        "  epoch, step = 0,0\r\n",
        "  results = []\r\n",
        "\r\n",
        "  for batch in tqdm(train_loader,total = train_loader.steps_per_epoch):\r\n",
        "    step += 1\r\n",
        "    inputs, target = batch\r\n",
        "    x,a,i = inputs\r\n",
        "    # print(x)\r\n",
        "    # target = target.reshape(-1, 1)\r\n",
        "    loss, acc = train_on_batch(inputs,target)\r\n",
        "    results.append((np.mean(loss),np.mean(acc)))\r\n",
        "\r\n",
        "    if step == train_loader.steps_per_epoch:\r\n",
        "      step = 0\r\n",
        "      epoch += 1\r\n",
        "      test_results = evaluate(test_loader)\r\n",
        "      print(test_results)\r\n",
        "      tarr = np.array(results)\r\n",
        "      ploss = np.mean(tarr[:,0])\r\n",
        "      pacc = np.mean(tarr[:,1])\r\n",
        "      ptloss = test_results[0]\r\n",
        "      ptacc = test_results[1]\r\n",
        "\r\n",
        "      # print(ptloss,ptacc)\r\n",
        "      print(\"Epoch: {} - \".format(epoch) + \\\r\n",
        "      \"Train loss: {:.3} Train Acc: {:.3} - \".format(ploss,pacc) + \\\r\n",
        "      \"Test loss: {:.3} Test Acc: {:.3}\".format(ptloss,ptacc))\r\n",
        "\r\n",
        "      if(epoch%2 == 1):\r\n",
        "        print(\"A single guess is right now:\")\r\n",
        "        i,t = batch\r\n",
        "        print(model(i,training = False),\"for a correct\", t)\r\n"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KDb4kjfNFYJI",
        "outputId": "be61ea62-988d-4253-cfda-8e8aa65dad70"
      },
      "source": [
        "# train_loader.steps_per_epoch\r\n",
        "\r\n",
        "model.compile()\r\n",
        "model.summary()"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_10\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "X_in (InputLayer)               [(None, 5)]          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "A_in (InputLayer)               [(None, None)]       0                                            \n",
            "__________________________________________________________________________________________________\n",
            "gcn_conv_40 (GCNConv)           (None, 32)           160         X_in[0][0]                       \n",
            "                                                                 A_in[0][0]                       \n",
            "__________________________________________________________________________________________________\n",
            "gcn_conv_41 (GCNConv)           (None, 16)           512         gcn_conv_40[0][0]                \n",
            "                                                                 A_in[0][0]                       \n",
            "__________________________________________________________________________________________________\n",
            "gcn_conv_42 (GCNConv)           (None, 16)           256         gcn_conv_41[0][0]                \n",
            "                                                                 A_in[0][0]                       \n",
            "__________________________________________________________________________________________________\n",
            "gcn_conv_43 (GCNConv)           (None, 16)           256         gcn_conv_42[0][0]                \n",
            "                                                                 A_in[0][0]                       \n",
            "__________________________________________________________________________________________________\n",
            "gcn_conv_44 (GCNConv)           (None, 30)           480         gcn_conv_43[0][0]                \n",
            "                                                                 A_in[0][0]                       \n",
            "__________________________________________________________________________________________________\n",
            "segment_ids_in (InputLayer)     [(None,)]            0                                            \n",
            "__________________________________________________________________________________________________\n",
            "global_sum_pool_2 (GlobalSumPoo (None, 30)           0           gcn_conv_44[0][0]                \n",
            "                                                                 segment_ids_in[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dense_10 (Dense)                (None, 7)            217         global_sum_pool_2[0][0]          \n",
            "==================================================================================================\n",
            "Total params: 1,881\n",
            "Trainable params: 1,881\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "43e770fbedc14903adafb77dca1f7c56",
            "904167b77cbc4900868b7a33782858ae",
            "89c94007491f4dd68b0c0da9420b7ffc",
            "a673b59f357747ef924d8fa54b50d414",
            "551b89e1db2840ca9dfe975971179949",
            "a53865e787d14e8ebd3400afc4f66331",
            "1eebe7523ce4404eaeaff32e69ea1a52",
            "bf81af2b542c4ceeb113e666944b8e04"
          ]
        },
        "id": "AFHoPS9-MMSO",
        "outputId": "fde3efff-58fd-4b90-f79c-87074f6f50fa"
      },
      "source": [
        "train_model(train_loader,test_loader)\r\n",
        "\r\n",
        "print('Evaluating model.')\r\n",
        "eval_results = evaluate(test_loader)\r\n",
        "\r\n",
        "print('Done.\\n' \r\n",
        "      'Test loss: {}\\n'\r\n",
        "      'Test accuracy: {}'.format(*eval_results))\r\n"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training model.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "43e770fbedc14903adafb77dca1f7c56",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=2667.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "[23709.68       72.69914]\n",
            "Epoch: 1 - Train loss: 1.3e+14 Train Acc: 3.13e+05 - Test loss: 2.37e+04 Test Acc: 72.7\n",
            "A single guess is right now:\n",
            "tf.Tensor(\n",
            "[[ 0.12440668  0.20931964  0.11185937 -0.39665404 -0.05907349 -0.43635502\n",
            "   0.12454455]\n",
            " [ 0.12440668  0.20931964  0.11185937 -0.39665404 -0.05907349 -0.43635502\n",
            "   0.12454455]\n",
            " [ 0.12440668  0.20931964  0.11185937 -0.39665404 -0.05907349 -0.43635502\n",
            "   0.12454455]\n",
            " [ 0.12440668  0.20931964  0.11185937 -0.39665404 -0.05907349 -0.43635502\n",
            "   0.12454455]\n",
            " [ 0.12440668  0.20931964  0.11185937 -0.39665404 -0.05907349 -0.43635502\n",
            "   0.12454455]\n",
            " [ 0.12440668  0.20931964  0.11185937 -0.39665404 -0.05907349 -0.43635502\n",
            "   0.12454455]\n",
            " [ 0.12440668  0.20931964  0.11185937 -0.39665404 -0.05907349 -0.43635502\n",
            "   0.12454455]\n",
            " [ 0.12440668  0.20931964  0.11185937 -0.39665404 -0.05907349 -0.43635502\n",
            "   0.12454455]\n",
            " [ 0.12440668  0.20931964  0.11185937 -0.39665404 -0.05907349 -0.43635502\n",
            "   0.12454455]\n",
            " [ 0.12440668  0.20931964  0.11185937 -0.39665404 -0.05907349 -0.43635502\n",
            "   0.12454455]\n",
            " [ 0.12440668  0.20931964  0.11185937 -0.39665404 -0.05907349 -0.43635502\n",
            "   0.12454455]\n",
            " [ 0.12440668  0.20931964  0.11185937 -0.39665404 -0.05907349 -0.43635502\n",
            "   0.12454455]\n",
            " [ 0.12440668  0.20931964  0.11185937 -0.39665404 -0.05907349 -0.43635502\n",
            "   0.12454455]\n",
            " [ 0.12440668  0.20931964  0.11185937 -0.39665404 -0.05907349 -0.43635502\n",
            "   0.12454455]\n",
            " [ 0.12440668  0.20931964  0.11185937 -0.39665404 -0.05907349 -0.43635502\n",
            "   0.12454455]\n",
            " [ 0.12440668  0.20931964  0.11185937 -0.39665404 -0.05907349 -0.43635502\n",
            "   0.12454455]\n",
            " [ 0.12440668  0.20931964  0.11185937 -0.39665404 -0.05907349 -0.43635502\n",
            "   0.12454455]\n",
            " [ 0.12440668  0.20931964  0.11185937 -0.39665404 -0.05907349 -0.43635502\n",
            "   0.12454455]\n",
            " [ 0.12440668  0.20931964  0.11185937 -0.39665404 -0.05907349 -0.43635502\n",
            "   0.12454455]\n",
            " [ 0.12440668  0.20931964  0.11185937 -0.39665404 -0.05907349 -0.43635502\n",
            "   0.12454455]], shape=(20, 7), dtype=float32) for a correct [[ 1.38464816e+00  1.37639867e+00 -1.16745598e+02 -3.35820632e+02\n",
            "  -6.81091653e-01  1.63481670e-01 -7.13714161e-01]\n",
            " [ 1.50568313e+00  1.30932408e+02 -3.48259348e+01 -1.89807734e+02\n",
            "   1.79062418e-01  8.01806609e-01 -5.70125260e-01]\n",
            " [ 1.63481701e+00  1.36121040e+02 -5.06506338e+01 -5.17181535e+02\n",
            "  -2.53178648e-01  7.60995051e-02  9.64421815e-01]\n",
            " [ 1.29301791e+00  5.54994488e+01 -8.95988698e+00 -2.18348628e+02\n",
            "   1.05073606e-01 -7.69757975e-01  6.29628618e-01]\n",
            " [ 2.00469144e+00 -1.02845038e+02 -2.04008011e+02 -2.04964207e+02\n",
            "  -3.09059215e-01  9.46826041e-01  8.94586480e-02]\n",
            " [ 1.93603501e+00 -1.85237585e+02  6.25404330e+01 -2.17550078e+02\n",
            "   8.97159317e-01  3.59156231e-01  2.57122464e-01]\n",
            " [ 1.47227637e+00  7.41916818e+01 -1.37809795e+02 -4.33069832e+02\n",
            "  -2.98041259e-01  7.89263089e-01  5.36875390e-01]\n",
            " [ 1.09399691e+00  5.93006555e+01 -8.09046643e+01 -5.00635851e+02\n",
            "   8.76467770e-01  3.44753804e-02  4.80224631e-01]\n",
            " [ 1.00117537e+00  1.23937668e+01  3.41340165e+01 -4.55586578e+02\n",
            "  -2.97261594e-01 -9.54140202e-01  3.53838934e-02]\n",
            " [ 1.51959797e+00  1.09509034e+02 -3.25206154e+01 -3.32800187e+02\n",
            "   8.86458931e-01 -1.38361494e-01 -4.41640873e-01]\n",
            " [ 9.72032439e-01 -8.37626199e+00  1.38352333e+01 -3.87960821e+02\n",
            "   8.06994808e-01 -4.41061254e-01  3.92714082e-01]\n",
            " [ 1.05740439e+00  1.05174054e+02 -6.02109817e+01 -2.77704583e+02\n",
            "  -3.35162453e-01 -6.69766168e-01  6.62630674e-01]\n",
            " [ 1.01212531e+00  8.65088955e+01 -6.37103440e+00 -4.71371155e+02\n",
            "   3.81255562e-01  8.76599027e-01  2.93629601e-01]\n",
            " [ 2.82110101e+00 -1.38164980e+02 -7.24968090e+01 -5.58498861e+02\n",
            "  -4.31646106e-01 -4.27547328e-01 -7.94282646e-01]\n",
            " [ 1.94147905e+00 -1.65281111e+02 -1.34564936e+01 -1.58218816e+02\n",
            "   1.08562536e-01  9.66398112e-01  2.32999709e-01]\n",
            " [ 2.34342175e+00 -6.60129979e+01 -6.89570913e+01 -4.30885356e+02\n",
            "   8.87454399e-01 -2.00408821e-01 -4.15043363e-01]\n",
            " [ 8.26978283e-01  5.75190857e+01 -1.06551479e+02 -3.40707755e+02\n",
            "   5.57953750e-01  5.78831668e-01  5.94677654e-01]\n",
            " [ 1.64691939e+00  5.98722902e+01  2.09783325e+01 -4.93471284e+02\n",
            "   2.90569032e-01  9.36766257e-01 -1.95034913e-01]\n",
            " [ 9.22329910e-01  7.17968684e+01 -8.88727234e+01 -3.71062329e+02\n",
            "  -4.70903897e-01  6.71224574e-01 -5.72457065e-01]\n",
            " [ 1.08345362e+00  1.98633400e+01  5.38859376e+01 -5.06792428e+02\n",
            "  -3.32050697e-01 -1.92548406e-01  9.23399938e-01]]\n",
            "[23532.521       74.422066]\n",
            "Epoch: 2 - Train loss: 6.48e+13 Train Acc: 1.57e+05 - Test loss: 2.35e+04 Test Acc: 74.4\n",
            "[21327.42      73.1521]\n",
            "Epoch: 3 - Train loss: 4.32e+13 Train Acc: 1.04e+05 - Test loss: 2.13e+04 Test Acc: 73.2\n",
            "A single guess is right now:\n",
            "tf.Tensor(\n",
            "[[ 0.12497731  0.21507369  0.09929352 -0.535455   -0.05905857 -0.43585944\n",
            "   0.12452923]\n",
            " [ 0.12497731  0.21507369  0.09929352 -0.535455   -0.05905857 -0.43585944\n",
            "   0.12452923]\n",
            " [ 0.12497731  0.21507369  0.09929352 -0.535455   -0.05905857 -0.43585944\n",
            "   0.12452923]\n",
            " [ 0.12497731  0.21507369  0.09929352 -0.535455   -0.05905857 -0.43585944\n",
            "   0.12452923]\n",
            " [ 0.12497731  0.21507369  0.09929352 -0.535455   -0.05905857 -0.43585944\n",
            "   0.12452923]\n",
            " [ 0.12497731  0.21507369  0.09929352 -0.535455   -0.05905857 -0.43585944\n",
            "   0.12452923]\n",
            " [ 0.12497731  0.21507369  0.09929352 -0.535455   -0.05905857 -0.43585944\n",
            "   0.12452923]\n",
            " [ 0.12497731  0.21507369  0.09929352 -0.535455   -0.05905857 -0.43585944\n",
            "   0.12452923]\n",
            " [ 0.12497731  0.21507369  0.09929352 -0.535455   -0.05905857 -0.43585944\n",
            "   0.12452923]\n",
            " [ 0.12497731  0.21507369  0.09929352 -0.535455   -0.05905857 -0.43585944\n",
            "   0.12452923]\n",
            " [ 0.12497731  0.21507369  0.09929352 -0.535455   -0.05905857 -0.43585944\n",
            "   0.12452923]\n",
            " [ 0.12497731  0.21507369  0.09929352 -0.535455   -0.05905857 -0.43585944\n",
            "   0.12452923]\n",
            " [ 0.12497731  0.21507369  0.09929352 -0.535455   -0.05905857 -0.43585944\n",
            "   0.12452923]\n",
            " [ 0.12497731  0.21507369  0.09929352 -0.535455   -0.05905857 -0.43585944\n",
            "   0.12452923]\n",
            " [ 0.12497731  0.21507369  0.09929352 -0.535455   -0.05905857 -0.43585944\n",
            "   0.12452923]\n",
            " [ 0.12497731  0.21507369  0.09929352 -0.535455   -0.05905857 -0.43585944\n",
            "   0.12452923]\n",
            " [ 0.12497731  0.21507369  0.09929352 -0.535455   -0.05905857 -0.43585944\n",
            "   0.12452923]\n",
            " [ 0.12497731  0.21507369  0.09929352 -0.535455   -0.05905857 -0.43585944\n",
            "   0.12452923]\n",
            " [ 0.12497731  0.21507369  0.09929352 -0.535455   -0.05905857 -0.43585944\n",
            "   0.12452923]\n",
            " [ 0.12497731  0.21507369  0.09929352 -0.535455   -0.05905857 -0.43585944\n",
            "   0.12452923]], shape=(20, 7), dtype=float32) for a correct [[ 3.33555207e+00  2.86726999e+01  1.19320429e+02 -6.14846483e+02\n",
            "   8.71345673e-01 -1.75727835e-01  4.58122741e-01]\n",
            " [ 8.61756899e-01  1.38484840e+02 -4.88172879e+01 -2.85245023e+02\n",
            "  -8.87869589e-01  3.81958829e-01 -2.56505452e-01]\n",
            " [ 1.12187771e+00  1.20465539e+02 -7.96175253e+01 -2.77801733e+02\n",
            "   2.67533929e-01  8.54714113e-01  4.44847593e-01]\n",
            " [ 1.39308234e+00  1.92919380e+01  2.59729731e+01 -3.02457191e+02\n",
            "  -3.22532726e-02 -9.12627443e-01 -4.07517947e-01]\n",
            " [ 5.06470010e-01 -1.82863046e+01 -7.15484198e+01 -4.06657704e+02\n",
            "   9.71094619e-01 -2.05508080e-01  1.21415279e-01]\n",
            " [ 1.15098774e+00 -6.14980982e+01 -6.03152197e+00 -3.70827028e+02\n",
            "   8.02361391e-03 -9.91319909e-01 -1.31226746e-01]\n",
            " [ 1.11766124e+00 -4.04085959e+01 -1.04027000e+01 -3.70633336e+02\n",
            "   7.71197764e-01  5.04572933e-01  3.88149668e-01]\n",
            " [ 1.70803957e+00 -2.95527440e+01  7.14546735e+01 -3.62439791e+02\n",
            "   8.09599861e-01  7.54495974e-02 -5.82112896e-01]\n",
            " [ 1.34735419e+00  2.99729116e+00 -6.23619829e+01 -3.02602667e+02\n",
            "   2.56570545e-01 -2.26548596e-01  9.39599537e-01]\n",
            " [ 1.09126866e+00  1.06931385e+02 -6.38091545e+01 -4.35723158e+02\n",
            "  -9.66722255e-01 -2.44803849e-01  7.42910321e-02]\n",
            " [ 5.68990172e-01  5.65794031e+01  3.97698013e+01 -4.17353542e+02\n",
            "  -9.54240404e-01 -1.21632758e-01  2.73186242e-01]\n",
            " [ 1.14212256e+00  9.24412689e+01 -9.21064100e+01 -2.85180619e+02\n",
            "  -9.75995562e-01 -6.08771184e-02  2.09109159e-01]\n",
            " [ 2.67899402e+00 -7.49326963e+01  4.56978053e+01 -5.44394994e+02\n",
            "   3.90364572e-01  6.68423108e-01 -6.33108244e-01]\n",
            " [ 1.63644521e+00  7.03404830e+01 -5.63070056e+01 -3.62059960e+02\n",
            "  -3.09732732e-01  2.59283044e-01  9.14788466e-01]\n",
            " [ 1.39188387e+00 -1.28512247e+02  4.48643837e+00 -3.60729782e+02\n",
            "  -9.25744345e-02 -8.99107701e-01  4.27826268e-01]\n",
            " [ 2.83938274e+00 -1.24822470e+02 -2.10676307e+02 -1.88802364e+02\n",
            "  -5.97277527e-02 -5.53445072e-01  8.30741324e-01]\n",
            " [ 8.13699004e-01  1.40100311e+02 -5.66271780e+01 -3.82729291e+02\n",
            "  -9.40679395e-01  1.21109214e-01 -3.16946107e-01]\n",
            " [ 2.15879632e+00 -1.57083472e+01  1.63119542e+01 -4.08147595e+02\n",
            "  -8.04576768e-01  1.75409223e-01  5.67351592e-01]\n",
            " [ 9.14981698e-01  5.89544818e+01 -1.05500980e+02 -3.23065543e+02\n",
            "  -3.42654086e-01  5.65194080e-02 -9.37759955e-01]\n",
            " [ 2.23590075e+00  2.28889688e+02 -4.83079708e+01 -4.89153734e+02\n",
            "  -3.95617884e-01 -9.14192795e-01  8.79660327e-02]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-33-de72dcc49112>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtest_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Evaluating model.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0meval_results\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-31-9369e8f396bf>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(train_loader, test_loader)\u001b[0m\n\u001b[1;32m    109\u001b[0m     \u001b[0;31m# print(x)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m     \u001b[0;31m# target = target.reshape(-1, 1)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 111\u001b[0;31m     \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0macc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_on_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    112\u001b[0m     \u001b[0mresults\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0macc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 828\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"xla\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    853\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    854\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 855\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    856\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    857\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2941\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   2942\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 2943\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   2944\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2945\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1917\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1918\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1919\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1920\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1921\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    558\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 560\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    561\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    562\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XDm2AcofIhfT"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}